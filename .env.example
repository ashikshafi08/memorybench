# ===================================================
# CodeChunkBench Environment Configuration
# ===================================================

# === REQUIRED: LLM API Keys for Evaluation ===
# At least one must be set based on your evaluation model choice

# Anthropic (Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI (GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# OpenRouter (Unified access to multiple models)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Google (Gemini models)
GOOGLE_API_KEY=your_google_api_key_here

# === OPTIONAL: Python Path for Chonkie Chunkers ===
# Required only if using chonkie-code or chonkie-recursive providers
# Must be Python 3.10+ with chonkie and tree-sitter-language-pack installed

# CHONKIE_PYTHON_PATH=python3

# ===================================================
# EXPERIMENTAL (Coming Soon)
# ===================================================
# These are for experimental memory providers, not required for code chunking.
# The memory provider integration is planned for future releases.

# Voyage AI (for AQRAG/ContextualRetrieval when implemented)
# VOYAGE_API_KEY=your_voyage_api_key_here

# Supermemory (experimental)
# SUPERMEMORY_API_KEY=your_supermemory_api_key_here
# SUPERMEMORY_API_URL=https://api.supermemory.ai/v1

# Mem0 (experimental)
# MEM0_API_KEY=your_mem0_api_key_here
# MEM0_BASE_URL=https://api.mem0.ai/v1

# PostgreSQL (for local memory providers when implemented)
# DATABASE_URL=postgresql://memorybench:memorybench@localhost:5433/memorybench
